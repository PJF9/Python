{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "gOElJ9FwZ0Cd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim, save\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "from pathlib import Path\n",
        "from os import cpu_count, remove"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torchinfo"
      ],
      "metadata": {
        "id": "zRyU9Nh9c5bo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary"
      ],
      "metadata": {
        "id": "dzfqlkZqc6UV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Device Agnostic Code"
      ],
      "metadata": {
        "id": "xCh9hWgfa6qD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4gwDSJUa4M8",
        "outputId": "547f295f-8b68-46fa-8104-6a86432447a1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initializing Model's Weights and Transforms"
      ],
      "metadata": {
        "id": "VI6dx0a2bA9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = models.ResNet18_Weights.DEFAULT\n",
        "transforms = weights.transforms()\n",
        "\n",
        "transforms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAKcVTCra-w-",
        "outputId": "e940e39c-5d43-4e66-b1c1-eb813409bc56"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageClassification(\n",
              "    crop_size=[224]\n",
              "    resize_size=[256]\n",
              "    mean=[0.485, 0.456, 0.406]\n",
              "    std=[0.229, 0.224, 0.225]\n",
              "    interpolation=InterpolationMode.BILINEAR\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Dataset"
      ],
      "metadata": {
        "id": "Sod5nET4b9JB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = CIFAR10(root=\"/content/\", download=True, transform=transforms, train=True)\n",
        "test_ds = CIFAR10(root=\"/content/\", download=True, transform=transforms, train=False)\n",
        "classes_names = test_ds.classes\n",
        "\n",
        "print(len(train_ds), len(test_ds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhy7I5p3b_G-",
        "outputId": "f08695ce-1211-46c8-d293-2912ca657fd5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 51413650.41it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/cifar-10-python.tar.gz to /content/\n",
            "Files already downloaded and verified\n",
            "50000 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the DeviceLoaders"
      ],
      "metadata": {
        "id": "c1Mb5ZVMcSmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DeviceLoader:\n",
        "    def __init__(self, dataset, device, batch_size=64, shuffle=True):\n",
        "        self.loader = DataLoader(\n",
        "            dataset=dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=shuffle,\n",
        "            num_workers=cpu_count(),\n",
        "            pin_memory=True\n",
        "        )\n",
        "        self.device = device\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __to_device(self, data):\n",
        "        if isinstance(data, (list, tuple)):\n",
        "            return [self.__to_device(x) for x in data]\n",
        "        return data.to(self.device, non_blocking=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.loader)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for batch in self.loader:\n",
        "            yield self.__to_device(batch)"
      ],
      "metadata": {
        "id": "xG_XPgTNcFYr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the Device Loaders\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dl = DeviceLoader(train_ds, device, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dl = DeviceLoader(test_ds, device, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(len(train_dl), len(test_dl))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSAnRce5ckya",
        "outputId": "1e4a1d60-e616-4422-d68c-b760f1e865bd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563 313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initializing the Model"
      ],
      "metadata": {
        "id": "W5Gg4VvycvEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resNet = models.resnet18(weights=weights).to(device)\n",
        "\n",
        "summary(model=resNet,\n",
        "        input_size=(1, 3, 224, 224),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFJEtF_7coCx",
        "outputId": "914c18c0-0f8f-44fa-aa42-6d32b46a242d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 152MB/s]\n",
            "/usr/local/lib/python3.9/dist-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
            "/usr/local/lib/python3.9/dist-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return super().__sizeof__() + self.nbytes()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "========================================================================================================================\n",
              "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
              "========================================================================================================================\n",
              "ResNet (ResNet)                          [1, 3, 224, 224]     [1, 1000]            --                   True\n",
              "├─Conv2d (conv1)                         [1, 3, 224, 224]     [1, 64, 112, 112]    9,408                True\n",
              "├─BatchNorm2d (bn1)                      [1, 64, 112, 112]    [1, 64, 112, 112]    128                  True\n",
              "├─ReLU (relu)                            [1, 64, 112, 112]    [1, 64, 112, 112]    --                   --\n",
              "├─MaxPool2d (maxpool)                    [1, 64, 112, 112]    [1, 64, 56, 56]      --                   --\n",
              "├─Sequential (layer1)                    [1, 64, 56, 56]      [1, 64, 56, 56]      --                   True\n",
              "│    └─BasicBlock (0)                    [1, 64, 56, 56]      [1, 64, 56, 56]      --                   True\n",
              "│    │    └─Conv2d (conv1)               [1, 64, 56, 56]      [1, 64, 56, 56]      36,864               True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]      [1, 64, 56, 56]      128                  True\n",
              "│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --\n",
              "│    │    └─Conv2d (conv2)               [1, 64, 56, 56]      [1, 64, 56, 56]      36,864               True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]      [1, 64, 56, 56]      128                  True\n",
              "│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --\n",
              "│    └─BasicBlock (1)                    [1, 64, 56, 56]      [1, 64, 56, 56]      --                   True\n",
              "│    │    └─Conv2d (conv1)               [1, 64, 56, 56]      [1, 64, 56, 56]      36,864               True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]      [1, 64, 56, 56]      128                  True\n",
              "│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --\n",
              "│    │    └─Conv2d (conv2)               [1, 64, 56, 56]      [1, 64, 56, 56]      36,864               True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]      [1, 64, 56, 56]      128                  True\n",
              "│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --\n",
              "├─Sequential (layer2)                    [1, 64, 56, 56]      [1, 128, 28, 28]     --                   True\n",
              "│    └─BasicBlock (0)                    [1, 64, 56, 56]      [1, 128, 28, 28]     --                   True\n",
              "│    │    └─Conv2d (conv1)               [1, 64, 56, 56]      [1, 128, 28, 28]     73,728               True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]     [1, 128, 28, 28]     256                  True\n",
              "│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --\n",
              "│    │    └─Conv2d (conv2)               [1, 128, 28, 28]     [1, 128, 28, 28]     147,456              True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]     [1, 128, 28, 28]     256                  True\n",
              "│    │    └─Sequential (downsample)      [1, 64, 56, 56]      [1, 128, 28, 28]     8,448                True\n",
              "│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --\n",
              "│    └─BasicBlock (1)                    [1, 128, 28, 28]     [1, 128, 28, 28]     --                   True\n",
              "│    │    └─Conv2d (conv1)               [1, 128, 28, 28]     [1, 128, 28, 28]     147,456              True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]     [1, 128, 28, 28]     256                  True\n",
              "│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --\n",
              "│    │    └─Conv2d (conv2)               [1, 128, 28, 28]     [1, 128, 28, 28]     147,456              True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]     [1, 128, 28, 28]     256                  True\n",
              "│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --\n",
              "├─Sequential (layer3)                    [1, 128, 28, 28]     [1, 256, 14, 14]     --                   True\n",
              "│    └─BasicBlock (0)                    [1, 128, 28, 28]     [1, 256, 14, 14]     --                   True\n",
              "│    │    └─Conv2d (conv1)               [1, 128, 28, 28]     [1, 256, 14, 14]     294,912              True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]     [1, 256, 14, 14]     512                  True\n",
              "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
              "│    │    └─Conv2d (conv2)               [1, 256, 14, 14]     [1, 256, 14, 14]     589,824              True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]     [1, 256, 14, 14]     512                  True\n",
              "│    │    └─Sequential (downsample)      [1, 128, 28, 28]     [1, 256, 14, 14]     33,280               True\n",
              "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
              "│    └─BasicBlock (1)                    [1, 256, 14, 14]     [1, 256, 14, 14]     --                   True\n",
              "│    │    └─Conv2d (conv1)               [1, 256, 14, 14]     [1, 256, 14, 14]     589,824              True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]     [1, 256, 14, 14]     512                  True\n",
              "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
              "│    │    └─Conv2d (conv2)               [1, 256, 14, 14]     [1, 256, 14, 14]     589,824              True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]     [1, 256, 14, 14]     512                  True\n",
              "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
              "├─Sequential (layer4)                    [1, 256, 14, 14]     [1, 512, 7, 7]       --                   True\n",
              "│    └─BasicBlock (0)                    [1, 256, 14, 14]     [1, 512, 7, 7]       --                   True\n",
              "│    │    └─Conv2d (conv1)               [1, 256, 14, 14]     [1, 512, 7, 7]       1,179,648            True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]       [1, 512, 7, 7]       1,024                True\n",
              "│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --\n",
              "│    │    └─Conv2d (conv2)               [1, 512, 7, 7]       [1, 512, 7, 7]       2,359,296            True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]       [1, 512, 7, 7]       1,024                True\n",
              "│    │    └─Sequential (downsample)      [1, 256, 14, 14]     [1, 512, 7, 7]       132,096              True\n",
              "│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --\n",
              "│    └─BasicBlock (1)                    [1, 512, 7, 7]       [1, 512, 7, 7]       --                   True\n",
              "│    │    └─Conv2d (conv1)               [1, 512, 7, 7]       [1, 512, 7, 7]       2,359,296            True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]       [1, 512, 7, 7]       1,024                True\n",
              "│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --\n",
              "│    │    └─Conv2d (conv2)               [1, 512, 7, 7]       [1, 512, 7, 7]       2,359,296            True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]       [1, 512, 7, 7]       1,024                True\n",
              "│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --\n",
              "├─AdaptiveAvgPool2d (avgpool)            [1, 512, 7, 7]       [1, 512, 1, 1]       --                   --\n",
              "├─Linear (fc)                            [1, 512]             [1, 1000]            513,000              True\n",
              "========================================================================================================================\n",
              "Total params: 11,689,512\n",
              "Trainable params: 11,689,512\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 1.81\n",
              "========================================================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 39.75\n",
              "Params size (MB): 46.76\n",
              "Estimated Total Size (MB): 87.11\n",
              "========================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Freezing Model's Parameters"
      ],
      "metadata": {
        "id": "6YYWGyaldI_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in resNet.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "n8bAW9NldE_P"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adjusting the Output Layer"
      ],
      "metadata": {
        "id": "s83yBi9_dXmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resNet.fc = nn.Linear(resNet.fc.in_features, 10).to(device)\n",
        "\n",
        "summary(model=resNet,\n",
        "        input_size=(1, 3, 224, 224),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n470g5QQdU3H",
        "outputId": "30a612dc-9ff2-441b-faab-3a6a8b773c64"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "========================================================================================================================\n",
              "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
              "========================================================================================================================\n",
              "ResNet (ResNet)                          [1, 3, 224, 224]     [1, 10]              --                   Partial\n",
              "├─Conv2d (conv1)                         [1, 3, 224, 224]     [1, 64, 112, 112]    (9,408)              False\n",
              "├─BatchNorm2d (bn1)                      [1, 64, 112, 112]    [1, 64, 112, 112]    (128)                False\n",
              "├─ReLU (relu)                            [1, 64, 112, 112]    [1, 64, 112, 112]    --                   --\n",
              "├─MaxPool2d (maxpool)                    [1, 64, 112, 112]    [1, 64, 56, 56]      --                   --\n",
              "├─Sequential (layer1)                    [1, 64, 56, 56]      [1, 64, 56, 56]      --                   False\n",
              "│    └─BasicBlock (0)                    [1, 64, 56, 56]      [1, 64, 56, 56]      --                   False\n",
              "│    │    └─Conv2d (conv1)               [1, 64, 56, 56]      [1, 64, 56, 56]      (36,864)             False\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]      [1, 64, 56, 56]      (128)                False\n",
              "│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --\n",
              "│    │    └─Conv2d (conv2)               [1, 64, 56, 56]      [1, 64, 56, 56]      (36,864)             False\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]      [1, 64, 56, 56]      (128)                False\n",
              "│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --\n",
              "│    └─BasicBlock (1)                    [1, 64, 56, 56]      [1, 64, 56, 56]      --                   False\n",
              "│    │    └─Conv2d (conv1)               [1, 64, 56, 56]      [1, 64, 56, 56]      (36,864)             False\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]      [1, 64, 56, 56]      (128)                False\n",
              "│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --\n",
              "│    │    └─Conv2d (conv2)               [1, 64, 56, 56]      [1, 64, 56, 56]      (36,864)             False\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]      [1, 64, 56, 56]      (128)                False\n",
              "│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --\n",
              "├─Sequential (layer2)                    [1, 64, 56, 56]      [1, 128, 28, 28]     --                   False\n",
              "│    └─BasicBlock (0)                    [1, 64, 56, 56]      [1, 128, 28, 28]     --                   False\n",
              "│    │    └─Conv2d (conv1)               [1, 64, 56, 56]      [1, 128, 28, 28]     (73,728)             False\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]     [1, 128, 28, 28]     (256)                False\n",
              "│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --\n",
              "│    │    └─Conv2d (conv2)               [1, 128, 28, 28]     [1, 128, 28, 28]     (147,456)            False\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]     [1, 128, 28, 28]     (256)                False\n",
              "│    │    └─Sequential (downsample)      [1, 64, 56, 56]      [1, 128, 28, 28]     (8,448)              False\n",
              "│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --\n",
              "│    └─BasicBlock (1)                    [1, 128, 28, 28]     [1, 128, 28, 28]     --                   False\n",
              "│    │    └─Conv2d (conv1)               [1, 128, 28, 28]     [1, 128, 28, 28]     (147,456)            False\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]     [1, 128, 28, 28]     (256)                False\n",
              "│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --\n",
              "│    │    └─Conv2d (conv2)               [1, 128, 28, 28]     [1, 128, 28, 28]     (147,456)            False\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]     [1, 128, 28, 28]     (256)                False\n",
              "│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --\n",
              "├─Sequential (layer3)                    [1, 128, 28, 28]     [1, 256, 14, 14]     --                   False\n",
              "│    └─BasicBlock (0)                    [1, 128, 28, 28]     [1, 256, 14, 14]     --                   False\n",
              "│    │    └─Conv2d (conv1)               [1, 128, 28, 28]     [1, 256, 14, 14]     (294,912)            False\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                False\n",
              "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
              "│    │    └─Conv2d (conv2)               [1, 256, 14, 14]     [1, 256, 14, 14]     (589,824)            False\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                False\n",
              "│    │    └─Sequential (downsample)      [1, 128, 28, 28]     [1, 256, 14, 14]     (33,280)             False\n",
              "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
              "│    └─BasicBlock (1)                    [1, 256, 14, 14]     [1, 256, 14, 14]     --                   False\n",
              "│    │    └─Conv2d (conv1)               [1, 256, 14, 14]     [1, 256, 14, 14]     (589,824)            False\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                False\n",
              "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
              "│    │    └─Conv2d (conv2)               [1, 256, 14, 14]     [1, 256, 14, 14]     (589,824)            False\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]     [1, 256, 14, 14]     (512)                False\n",
              "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
              "├─Sequential (layer4)                    [1, 256, 14, 14]     [1, 512, 7, 7]       --                   False\n",
              "│    └─BasicBlock (0)                    [1, 256, 14, 14]     [1, 512, 7, 7]       --                   False\n",
              "│    │    └─Conv2d (conv1)               [1, 256, 14, 14]     [1, 512, 7, 7]       (1,179,648)          False\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]       [1, 512, 7, 7]       (1,024)              False\n",
              "│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --\n",
              "│    │    └─Conv2d (conv2)               [1, 512, 7, 7]       [1, 512, 7, 7]       (2,359,296)          False\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]       [1, 512, 7, 7]       (1,024)              False\n",
              "│    │    └─Sequential (downsample)      [1, 256, 14, 14]     [1, 512, 7, 7]       (132,096)            False\n",
              "│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --\n",
              "│    └─BasicBlock (1)                    [1, 512, 7, 7]       [1, 512, 7, 7]       --                   False\n",
              "│    │    └─Conv2d (conv1)               [1, 512, 7, 7]       [1, 512, 7, 7]       (2,359,296)          False\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]       [1, 512, 7, 7]       (1,024)              False\n",
              "│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --\n",
              "│    │    └─Conv2d (conv2)               [1, 512, 7, 7]       [1, 512, 7, 7]       (2,359,296)          False\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]       [1, 512, 7, 7]       (1,024)              False\n",
              "│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --\n",
              "├─AdaptiveAvgPool2d (avgpool)            [1, 512, 7, 7]       [1, 512, 1, 1]       --                   --\n",
              "├─Linear (fc)                            [1, 512]             [1, 10]              5,130                True\n",
              "========================================================================================================================\n",
              "Total params: 11,181,642\n",
              "Trainable params: 5,130\n",
              "Non-trainable params: 11,176,512\n",
              "Total mult-adds (G): 1.81\n",
              "========================================================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 39.74\n",
              "Params size (MB): 44.73\n",
              "Estimated Total Size (MB): 85.07\n",
              "========================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the Training and Evaluating Loops"
      ],
      "metadata": {
        "id": "yDBDU9gpd0EJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_step(model, train_dl, loss_fn, eval_fn, opt):\n",
        "    from tqdm import tqdm # For the progress bar\n",
        "    \n",
        "\n",
        "    # Setting batch size and model's device\n",
        "    batch_size = train_dl.batch_size\n",
        "    model_device = next(model.parameters()).device\n",
        "\n",
        "    # Initialize training loss and accuracy\n",
        "    train_loss, train_eval = 0, 0\n",
        "\n",
        "    print(\"\\tTraining Step: \", end=\"\")\n",
        "\n",
        "    model.train()\n",
        "    for x_train, y_train in tqdm(train_dl):\n",
        "        # Moving batches to device\n",
        "        x_train, y_train = x_train.to(model_device, non_blocking=True), y_train.to(model_device, non_blocking=True)\n",
        "\n",
        "        # Generating predictions\n",
        "        model_logits = model(x_train)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_fn(model_logits, y_train)\n",
        "        train_loss += loss.item()\n",
        "        train_eval += eval_fn(model_logits, y_train)\n",
        "\n",
        "        # Updating Model's parameters\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    train_loss /= len(train_dl)\n",
        "    train_eval /= len(train_dl)\n",
        "\n",
        "    return train_loss, train_eval"
      ],
      "metadata": {
        "id": "UIuSUFxydu-G"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation_step(model, valid_dl, loss_fn, eval_fn):\n",
        "    import torch\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    # Setting batch size and model's device\n",
        "    batch_size = valid_dl.batch_size\n",
        "    model_device = next(model.parameters()).device\n",
        "\n",
        "    # Initialize validation loss and accuracy\n",
        "    valid_loss, valid_eval = 0, 0\n",
        "\n",
        "    print(\"\\tValidation Step: \", end=\"\")\n",
        "\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for x_valid, y_valid in tqdm(valid_dl):\n",
        "            # Moving batches to model's device\n",
        "            x_valid, y_valid = x_valid.to(model_device, non_blocking=True), y_valid.to(model_device, non_blocking=True)\n",
        "\n",
        "            # Generate Predictions\n",
        "            model_logits = model(x_valid)\n",
        "\n",
        "            valid_loss += loss_fn(model_logits, y_valid).item()\n",
        "            valid_eval += eval_fn(model_logits, y_valid)\n",
        "\n",
        "        valid_loss /= len(valid_dl)\n",
        "        valid_eval /= len(valid_dl)\n",
        "\n",
        "        return valid_loss, valid_eval"
      ],
      "metadata": {
        "id": "OpqzrkbWd6v1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(model, epochs, train_dl, valid_dl, loss_fn, eval_fn, opt):\n",
        "    from timeit import default_timer as timer\n",
        "    import torch\n",
        "\n",
        "\n",
        "    # Starting the `timer` and initialize the evaluating Lists\n",
        "    start_time = timer()\n",
        "    train_losses, train_evals = [], []\n",
        "    valid_losses, valid_evals = [], []\n",
        "\n",
        "    print(\"Starting Process...\\n\")\n",
        "    \n",
        "    for epoch in range(1, epochs + 1):\n",
        "        print(f\"-> Epoch: {epoch}/{epochs}\")\n",
        "\n",
        "        # Training and Evaluating the Model\n",
        "        train_loss, train_eval = training_step(model, train_dl, loss_fn, eval_fn, opt)\n",
        "        valid_loss, valid_eval = validation_step(model, valid_dl, loss_fn, eval_fn)\n",
        "\n",
        "        print()\n",
        "        print(\n",
        "            f\"   Train Loss: {train_loss:.4f} | \"\n",
        "            f\"Train Accuracy: {train_eval:.2f}% | \"\n",
        "            f\"Valid Loss: {valid_loss:.4f} | \"\n",
        "            f\"Valid Accuracy (%): {valid_eval:.2f}%\")\n",
        "        print(\"-\" * 99, end=\"\\n\\n\")\n",
        "        \n",
        "        train_losses.append(train_loss)\n",
        "        train_evals.append(train_eval)\n",
        "        valid_losses.append(valid_loss)\n",
        "        valid_evals.append(valid_eval)\n",
        "\n",
        "    print(\"Process Completed Successfully...\")\n",
        "\n",
        "    return {\"model_train_loss\": train_losses,\n",
        "        \"model_train_eval\": train_evals,\n",
        "        \"model_valid_loss\": valid_losses,\n",
        "        \"model_valid_eval\": valid_evals,\n",
        "        \"model_name\": model.__class__.__name__,\n",
        "        \"model_loss_fn\": loss_fn.__class__.__name__,\n",
        "        \"model_evaluating_m\": eval_fn.__name__,\n",
        "        \"model_optimizer\": opt.__class__.__name__,\n",
        "        \"model_device\": next(model.parameters()).device.type,\n",
        "        \"model_epochs\": epochs,\n",
        "        \"model_time\": timer() - start_time}"
      ],
      "metadata": {
        "id": "Z-urVKEUd8cl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Accuracy Metric"
      ],
      "metadata": {
        "id": "-wFlu1wkeAvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_fn(model_logits, labels):\n",
        "    preds = torch.softmax(model_logits, dim=1).argmax(dim=1)\n",
        "\n",
        "    return (preds == labels).sum().item() / len(labels)"
      ],
      "metadata": {
        "id": "W0UtRuQRd-St"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Loss Function and Optimizer"
      ],
      "metadata": {
        "id": "87hzsbeieEec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = optim.Adam(params=resNet.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "kYxgne5WeD69"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model"
      ],
      "metadata": {
        "id": "IbocQFiOeP13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = fit(model=resNet,\n",
        "          epochs=3,\n",
        "          train_dl=train_dl,\n",
        "          valid_dl=test_dl,\n",
        "          loss_fn=loss_fn,\n",
        "          eval_fn=accuracy_fn,\n",
        "          opt=opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGj2Hc5feKhd",
        "outputId": "d0e1ddb9-88b6-418c-9f2e-a4d7d7246182"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Process...\n",
            "\n",
            "-> Epoch: 1/3\n",
            "\tTraining Step: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [02:19<00:00, 11.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tValidation Step: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:26<00:00, 11.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "   Train Loss: 0.6779 | Train Accuracy: 0.76% | Valid Loss: 0.6545 | Valid Accuracy (%): 0.77%\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "-> Epoch: 2/3\n",
            "\tTraining Step: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [02:20<00:00, 11.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tValidation Step: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:27<00:00, 11.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "   Train Loss: 0.6617 | Train Accuracy: 0.77% | Valid Loss: 0.6476 | Valid Accuracy (%): 0.78%\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "-> Epoch: 3/3\n",
            "\tTraining Step: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1563/1563 [02:18<00:00, 11.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tValidation Step: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:28<00:00, 11.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "   Train Loss: 0.6686 | Train Accuracy: 0.77% | Valid Loss: 0.6290 | Valid Accuracy (%): 0.79%\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "Process Completed Successfully...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the Model"
      ],
      "metadata": {
        "id": "ignPR5dJo0m3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, saved_model_path: str, if_exists_stop=False):\n",
        "    target_path = Path('/'.join(saved_model_path.split('/')[:-1]))\n",
        "    model_name = saved_model_path.split('/')[-1]\n",
        "\n",
        "    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"Wrong extension: Expecting `.pt` or `.pth`...\"\n",
        "    \n",
        "    if not target_path.exists():\n",
        "        target_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if (target_path / model_name).is_file():\n",
        "        print(f\"[INFO] Model `{model_name}` already exists on `{target_path}`...\")\n",
        "\n",
        "        if if_exists_stop:\n",
        "            return\n",
        "\n",
        "        print(f\"[INFO] Deleting `{target_path / model_name}`...\")\n",
        "        remove(target_path / model_name)\n",
        "\n",
        "    print(f\"[INFO] Saving Model `{model_name}` to `{target_path}`...\")\n",
        "    save(obj=model.state_dict(), f=target_path/model_name)\n",
        "\n",
        "    print(f\"[INFO] Model Successfully Saved to {target_path / model_name}\")"
      ],
      "metadata": {
        "id": "fu8-E-xueYbH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(resNet, \"/content/models/resNet.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEznq7rMpNCr",
        "outputId": "2f56c697-193b-40ef-8491-1c71bc46a10e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Saving Model `resNet.pth` to `/content/models`...\n",
            "[INFO] Model Successfully Saved to /content/models/resNet.pth\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}